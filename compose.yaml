compose:
  - call: lcod://axiom/path/join@1
    in:
      base: $.projectPath
      segment: "lcp.toml"
    out:
      descriptorPath: path

  - call: lcod://axiom/fs/read-file@1
    in:
      path: $.descriptorPath
      encoding: "utf-8"
    out:
      descriptorText: data

  - call: lcod://axiom/toml/parse@1
    in:
      text: $.descriptorText
    out:
      descriptor: value

  - call: lcod://tooling/script@1
    in:
      source: |
        async ({ state }) => ({
          hasConfigPath: typeof state.configPath === 'string' && state.configPath.trim().length > 0
        })
      input:
        configPath: $.configPath
    out:
      hasConfigPath: hasConfigPath

  - call: lcod://flow/if@1
    in:
      cond: $.hasConfigPath
    out:
      configText: configText
    children:
      then:
        - call: lcod://axiom/fs/read-file@1
          in:
            path: $.configPath
            encoding: "utf-8"
          out:
            configText: data
      else:
        - call: lcod://axiom/path/join@1
          in:
            base: $.projectPath
            segment: "resolve.config.json"
          out:
            defaultConfigPath: path
        - call: lcod://tooling/script@1
          in:
            source: |
              async ({ state, imports }) => {
                const fallback = '{"sources":{}}';
                const path = typeof state?.defaultPath === 'string' ? state.defaultPath : null;
                if (!path) return { configText: fallback };
                try {
                  const file = await imports.fsReadFile({ path, encoding: 'utf-8' });
                  return { configText: file?.data ?? fallback };
                } catch (err) {
                  return { configText: fallback, warning: `Failed to read ${path}: ${err.message}` };
                }
              }
            input:
              defaultPath: $.defaultConfigPath
            imports:
              fsReadFile: lcod://axiom/fs/read-file@1
          out:
            configText: configText
            configWarning: warning

  - call: lcod://tooling/script@1
    in:
      source: |
        async ({ state }) => ({
          hasConfigText: typeof state.configText === 'string' && state.configText.trim().length > 0
        })
      input:
        configText: $.configText
    out:
      hasConfigText: hasConfigText

  - call: lcod://flow/if@1
    in:
      cond: $.hasConfigText
    out:
      resolverConfig: resolverConfig
    children:
      then:
        - call: lcod://axiom/json/parse@1
          in:
            text: $.configText
          out:
            resolverConfig: value
      else:
        - call: lcod://impl/set@1
          in:
            resolverConfig:
              sources: {}
          out:
            resolverConfig: resolverConfig

  - call: lcod://flow/if@1
    in:
      cond: $.outputPath
    children:
      then:
        - call: lcod://impl/set@1
          in:
            lockPath: $.outputPath
          out:
            lockPath: lockPath
      else:
        - call: lcod://axiom/path/join@1
          in:
            base: $.projectPath
            segment: "lcp.lock"
          out:
            lockPath: path
    out:
      lockPath: lockPath

  - call: lcod://tooling/script@1
    in:
      source: |
        async ({ state, imports }, api) => {
          const warnings = [];
          if (typeof state?.configWarning === 'string' && state.configWarning) {
            warnings.push(state.configWarning);
          }
          const config = typeof state?.config === 'object' && state.config ? state.config : {};
          const sources = typeof config.sources === 'object' && config.sources ? config.sources : {};
          const projectPath = typeof state?.projectPath === 'string' && state.projectPath
            ? state.projectPath
            : process.cwd();

          const cacheInfo = await imports.cacheDir({ projectPath });
          const cacheRootRaw = cacheInfo?.path || projectPath;
          const normalised = await api.call('lcod://axiom/path/join@1', { base: cacheRootRaw, segment: '.' });
          const cacheRoot = normalised?.path || cacheRootRaw;

          const resolved = new Map();

          const hashHex = async (text) => {
            const res = await imports.hash({ data: text, encoding: 'utf-8' });
            return res?.hex ? `sha256-${res.hex}` : undefined;
          };

          const parseToml = async (text) => {
            const parsed = await imports.tomlParse({ text });
            return parsed?.value || {};
          };

          const joinPath = async (base, segment) => {
            const joined = await imports.pathJoin({ base, segment });
            return joined?.path || base;
          };

          const readDescriptor = async (descriptorPath) => {
            const file = await imports.fsReadFile({ path: descriptorPath, encoding: 'utf-8' });
            const text = file?.data ?? '';
            const descriptor = await parseToml(text);
            const integrity = await hashHex(text);
            const requires = Array.isArray(descriptor?.deps?.requires) ? descriptor.deps.requires : [];
            return { descriptor, descriptorText: text, integrity, childIds: requires };
          };

          const resolvePathSpec = async (spec, preload) => {
            const basePath = spec.path && (spec.path.startsWith('/') || spec.path.startsWith('~'))
              ? spec.path
              : await joinPath(projectPath, spec.path || '.');
            if (preload && preload.descriptor && preload.descriptorText) {
              const integrity = await hashHex(preload.descriptorText);
              const childIds = Array.isArray(preload.descriptor?.deps?.requires) ? preload.descriptor.deps.requires : [];
              return {
                descriptor: preload.descriptor,
                descriptorText: preload.descriptorText,
                integrity,
                source: preload.source || { type: 'path', path: basePath },
                childIds
              };
            }
            const descriptorPath = await joinPath(basePath, 'lcp.toml');
            const data = await readDescriptor(descriptorPath);
            return {
              ...data,
              source: { type: 'path', path: basePath }
            };
          };

          const resolveGitSpec = async (id, spec) => {
            if (typeof spec.url !== 'string' || !spec.url) {
              throw new Error(`Missing git url for ${id}`);
            }
            const keyPayload = JSON.stringify({ id, url: spec.url, ref: spec.ref ?? null, subdir: spec.subdir ?? null });
            const keyHash = await imports.hash({ data: keyPayload, encoding: 'utf-8' });
            const repoRoot = await joinPath(cacheRoot, 'git');
            const repoDir = await joinPath(repoRoot, keyHash?.hex || 'repo');
            const descriptorRoot = spec.subdir ? await joinPath(repoDir, spec.subdir) : repoDir;
            const descriptorPath = await joinPath(descriptorRoot, 'lcp.toml');

            let data;
            let cloneMeta = null;
            try {
              data = await readDescriptor(descriptorPath);
            } catch (err) {
              const cloneInput = { url: spec.url, dest: repoDir };
              if (spec.ref) cloneInput.ref = spec.ref;
              if (spec.depth) cloneInput.depth = spec.depth;
              if (spec.subdir) cloneInput.subdir = spec.subdir;
              if (spec.auth) cloneInput.auth = spec.auth;
              cloneMeta = await imports.gitClone(cloneInput);
              data = await readDescriptor(descriptorPath);
            }

            const source = {
              type: 'git',
              url: spec.url,
              path: descriptorRoot
            };
            if (spec.ref) source.ref = spec.ref;
            if (spec.subdir) source.subdir = spec.subdir;
            if (cloneMeta?.commit) source.commit = cloneMeta.commit;
            if (!source.ref && cloneMeta?.ref) source.ref = cloneMeta.ref;
            if (cloneMeta?.source?.fetchedAt) source.fetchedAt = cloneMeta.source.fetchedAt;

            return {
              descriptor: data.descriptor,
              descriptorText: data.descriptorText,
              integrity: data.integrity,
              source,
              childIds: data.childIds
            };
          };

          const resolveHttpSpec = async (id, spec) => {
            if (typeof spec.url !== 'string' || !spec.url) {
              throw new Error(`Missing http url for ${id}`);
            }
            const keyPayload = JSON.stringify({ id, url: spec.url, descriptorPath: spec.descriptorPath ?? null });
            const keyHash = await imports.hash({ data: keyPayload, encoding: 'utf-8' });
            const httpRoot = await joinPath(cacheRoot, 'http');
            const artifactDir = await joinPath(httpRoot, keyHash?.hex || 'artifact');
            const filename = typeof spec.filename === 'string' && spec.filename ? spec.filename : 'artifact.toml';
            const artifactPath = await joinPath(artifactDir, filename);
            const descriptorPath = spec.descriptorPath
              ? await joinPath(artifactDir, spec.descriptorPath)
              : artifactPath;

            let data;
            try {
              data = await readDescriptor(descriptorPath);
            } catch (err) {
              const downloadInput = { url: spec.url, path: artifactPath };
              if (spec.method) downloadInput.method = spec.method;
              if (spec.headers) downloadInput.headers = spec.headers;
              if (spec.query) downloadInput.query = spec.query;
              if (spec.timeoutMs) downloadInput.timeoutMs = spec.timeoutMs;
              if (spec.followRedirects !== undefined) downloadInput.followRedirects = spec.followRedirects;
              if (spec.body !== undefined) downloadInput.body = spec.body;
              if (spec.bodyEncoding) downloadInput.bodyEncoding = spec.bodyEncoding;
              await imports.httpDownload(downloadInput);
              data = await readDescriptor(descriptorPath);
            }

            const source = {
              type: 'http',
              url: spec.url,
              path: spec.descriptorPath ? artifactDir : descriptorPath
            };
            if (spec.descriptorPath) source.descriptorPath = spec.descriptorPath;
            if (spec.filename) source.filename = filename;

            return {
              descriptor: data.descriptor,
              descriptorText: data.descriptorText,
              integrity: data.integrity,
              source,
              childIds: data.childIds
            };
          };

          const loadSpec = async (id, spec, preload) => {
            if (spec?.type === 'path') return resolvePathSpec(spec, preload);
            if (spec?.type === 'git') return resolveGitSpec(id, spec);
            if (spec?.type === 'http') return resolveHttpSpec(id, spec);
            if (preload && preload.descriptor && preload.descriptorText) {
              const integrity = await hashHex(preload.descriptorText);
              const childIds = Array.isArray(preload.descriptor?.deps?.requires) ? preload.descriptor.deps.requires : [];
              return {
                descriptor: preload.descriptor,
                descriptorText: preload.descriptorText,
                integrity,
                source: preload.source || { type: 'path', path: projectPath },
                childIds
              };
            }
            return {
              descriptor: {},
              descriptorText: '',
              source: { type: 'registry', reference: id },
              childIds: []
            };
          };

          const resolveDependency = async (depId, stack = [], preload) => {
            const id = typeof depId === 'string' && depId ? depId : String(depId);
            if (resolved.has(id)) return resolved.get(id);
            if (stack.includes(id)) {
              warnings.push(`Dependency cycle detected: ${[...stack, id].join(' -> ')}`);
              return resolved.get(id);
            }

            const spec = preload?.source || sources[id];
            if (!spec) {
              warnings.push(`Missing source spec for ${id}`);
              const fallback = { id, source: { type: 'registry', reference: id }, dependencies: [] };
              resolved.set(id, fallback);
              return fallback;
            }

            let info;
            try {
              info = await loadSpec(id, spec, preload);
            } catch (err) {
              warnings.push(`Failed to load ${id}: ${err.message}`);
              const fallback = { id, source: { type: spec.type || 'unknown', reference: id }, dependencies: [] };
              resolved.set(id, fallback);
              return fallback;
            }

            const record = {
              id,
              source: info.source,
              dependencies: []
            };
            if (info.integrity) record.integrity = info.integrity;
            resolved.set(id, record);

            const childIds = Array.isArray(info.childIds) ? info.childIds : [];
            for (const child of childIds) {
              if (typeof child !== 'string' || !child) continue;
              try {
                const childRecord = await resolveDependency(child, [...stack, id]);
                if (childRecord) record.dependencies.push(childRecord);
              } catch (err) {
                warnings.push(`Failed to resolve ${child} for ${id}: ${err.message}`);
              }
            }

            return record;
          };

          const rootId = typeof state?.rootId === 'string' && state.rootId
            ? state.rootId
            : (state?.rootDescriptor && state.rootDescriptor.id);
          const preloadRoot = {
            descriptor: state?.rootDescriptor,
            descriptorText: state?.rootDescriptorText,
            source: { type: 'path', path: projectPath }
          };

          const root = rootId
            ? await resolveDependency(rootId, [], preloadRoot)
            : {
                id: undefined,
                source: { type: 'path', path: projectPath },
                dependencies: []
              };
          if (!rootId) {
            warnings.push('Root descriptor is missing an id');
          }

          return {
            root,
            warnings
          };
        }
      input:
        rootId: $.descriptor.id
        projectPath: $.projectPath
        config: $.resolverConfig
        rootDescriptor: $.descriptor
        rootDescriptorText: $.descriptorText
      imports:
        pathJoin: lcod://axiom/path/join@1
        fsReadFile: lcod://axiom/fs/read-file@1
        tomlParse: lcod://axiom/toml/parse@1
        hash: lcod://contract/core/hash/sha256@1
        gitClone: lcod://contract/core/git/clone@1
        httpDownload: lcod://axiom/http/download@1
        cacheDir: lcod://tooling/resolver/cache-dir@1
    out:
      resolverResult: $

  - call: lcod://tooling/script@1
    in:
      source: |
        async ({ state }) => {
          const root = state.root ?? {};
          return {
            dependencyGraph: Array.isArray(root.dependencies) ? root.dependencies : [],
            rootIntegrity: root.integrity || null,
            collectedWarnings: Array.isArray(state.warnings) ? state.warnings : []
          };
        }
      input:
        root: $.resolverResult.root
        warnings: $.resolverResult.warnings
    out:
      dependencyGraph: dependencyGraph
      rootIntegrity: rootIntegrity
      collectedWarnings: collectedWarnings

  - call: lcod://tooling/script@1
    in:
      source: |
        async ({ state }) => {
          const descriptor = state.descriptor ?? {};
          const component = {
            id: descriptor.id,
            resolved: descriptor.id,
            source: { type: 'path', path: '.' },
            dependencies: Array.isArray(state.dependencyGraph) ? state.dependencyGraph : []
          };
          if (state.rootIntegrity) component.integrity = state.rootIntegrity;
          return {
            lockDocument: {
              schemaVersion: '1.0',
              resolverVersion: '0.1.0',
              components: [component],
              warnings: Array.isArray(state.collectedWarnings) ? state.collectedWarnings : []
            }
          };
        }
      input:
        descriptor: $.descriptor
        dependencyGraph: $.dependencyGraph
        rootIntegrity: $.rootIntegrity
        collectedWarnings: $.collectedWarnings
    out:
      lockDocument: lockDocument

  - call: lcod://axiom/toml/stringify@1
    in:
      value: $.lockDocument
    out:
      lockText: text

  - call: lcod://axiom/fs/write-file@1
    in:
      path: $.lockPath
      data: $.lockText
      createParents: true
    out:
      ok: wrote

  - call: lcod://impl/set@1
    in:
      lockPath: $.lockPath
      components: $.lockDocument.components
      warnings: $.lockDocument.warnings
    out:
      lockPath: lockPath
      components: components
      warnings: warnings
